{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import warnings\n",
    "import scipy.ndimage as ndi\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sys\n",
    "import re\n",
    "from skimage.filters import gaussian, median\n",
    "from skimage import io\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import hessian_matrix\n",
    "from skimage.measure import *\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils import shuffle\n",
    "from skimage.morphology import *\n",
    "from matplotlib.widgets import Button, TextBox\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Optional, Dict, Any, Union\n",
    "from pathlib import Path\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_lim = [256, 256, 149]\n",
    "clusters = 6 # Numero di cluster per il k-means (default = 6)\n",
    "path_img = 'test_data.tif'\n",
    "sig_G = [0]\n",
    "\n",
    "# Raccogli informazioni dall'intestazione dell'immagine\n",
    "with tifffile.TiffFile('test_data.tif') as tif:\n",
    "    # Get the image array\n",
    "    info1 = tif.asarray()\n",
    "Nz = len(info1)\n",
    "Ny = info1[0].shape[1]\n",
    "Nx = info1[0].shape[0]\n",
    "tp = info1[0].dtype\n",
    "\n",
    "if tp == 'uint16': \n",
    "    bit = 16\n",
    "elif tp == 'uint8':\n",
    "    bit = 8\n",
    "else:\n",
    "    raise ValueError('input image must be 8 or 16 bit')\n",
    "\n",
    "nxiL = list(range(0, Nx, size_lim[0]))\n",
    "nxeL = [min(Nx, i) for i in range(size_lim[0], Nx + size_lim[0], size_lim[0])]\n",
    "nyiL = list(range(0, Ny, size_lim[1]))\n",
    "nyeL = [min(Ny, i) for i in range(size_lim[1], Ny + size_lim[1], size_lim[1])]\n",
    "th_back = 0.02 * (2 ** bit)\n",
    "win = size_lim[2]  # Dimensione del ritaglio lungo l'asse z\n",
    "safe = 3  # Margine z\n",
    "safe_xy = 3  # Margine xy\n",
    "k_seq = list(range(0, Nz, win))  # Numero di fette dell'immagine iniziale lungo l'asse z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = tif.pages[0].tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_tags = ['XResolution', 'YResolution']\n",
    "res = [1, 1, 1]\n",
    "for i,res_tag in enumerate(res_tags):\n",
    "    if res_tag in tags:\n",
    "        res[i] = 1 / (tags[res_tag].value[0] / tags[res_tag].value[1])\n",
    "\n",
    "strinfo = tags['ImageDescription'].value\n",
    "um = strinfo.find('spacing=')\n",
    "cut_s = len('spacing=')\n",
    "res[2] = zres = float(re.search(r'\\d+\\.\\d+', strinfo[um + cut_s:]).group(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of clusters is: 6\n",
      "crop is x(0:256), y(0:256)\n",
      "starting with slice 0 over 143, window set to 149\n",
      "1st of 1 passes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x1/cw0t9qw9547b5jd05cm3d2vr0000gn/T/ipykernel_97569/2747371345.py:58: FutureWarning: use_gaussian_derivatives currently defaults to False, but will change to True in a future version. Please specify this argument explicitly to maintain the current behavior\n",
      "  Hxx, Hxy, Hxz, Hyy, Hyz, Hzz = hessian_matrix(Gx2, sigma=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of clusters is: 6\n",
      "crop is x(0:256), y(256:512)\n",
      "starting with slice 0 over 143, window set to 149\n",
      "1st of 1 passes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x1/cw0t9qw9547b5jd05cm3d2vr0000gn/T/ipykernel_97569/2747371345.py:58: FutureWarning: use_gaussian_derivatives currently defaults to False, but will change to True in a future version. Please specify this argument explicitly to maintain the current behavior\n",
      "  Hxx, Hxy, Hxz, Hyy, Hyz, Hzz = hessian_matrix(Gx2, sigma=1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[140], line 117\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Clustering k-means only if enough samples\u001b[39;00m\n\u001b[1;32m    116\u001b[0m kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39mclusters, n_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m--> 117\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mkmeans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkm_in1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m resiz_km[mask_back] \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m    119\u001b[0m TOT_KM1 \u001b[38;5;241m=\u001b[39m resiz_km\u001b[38;5;241m.\u001b[39mreshape((NxC, NyC, NzC))\n",
      "File \u001b[0;32m~/Desktop/PhD/Code/Senpai_python/.venv/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1064\u001b[0m, in \u001b[0;36m_BaseKMeans.fit_predict\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute cluster centers and predict cluster index for each sample.\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \n\u001b[1;32m   1044\u001b[0m \u001b[38;5;124;03m    Convenience method; equivalent to calling fit(X) followed by\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;124;03m        Index of the cluster each sample belongs to.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[0;32m~/Desktop/PhD/Code/Senpai_python/.venv/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/PhD/Code/Senpai_python/.venv/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1510\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1507\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitialization complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;66;03m# run a k-means once\u001b[39;00m\n\u001b[0;32m-> 1510\u001b[0m labels, inertia, centers, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43mkmeans_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1512\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcenters_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_n_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1518\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[38;5;66;03m# determine if these results are the best so far\u001b[39;00m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;66;03m# we chose a new run if it has a better inertia and the clustering is\u001b[39;00m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# different from the best so far (it's possible that the inertia is\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# slightly better even if the clustering is the same with potentially\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;66;03m# permuted labels, due to rounding errors)\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_inertia \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1526\u001b[0m     inertia \u001b[38;5;241m<\u001b[39m best_inertia\n\u001b[1;32m   1527\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_same_clustering(labels, best_labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters)\n\u001b[1;32m   1528\u001b[0m ):\n",
      "File \u001b[0;32m~/Desktop/PhD/Code/Senpai_python/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:165\u001b[0m, in \u001b[0;36m_threadpool_controller_decorator.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m controller \u001b[38;5;241m=\u001b[39m _get_threadpool_controller()\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m controller\u001b[38;5;241m.\u001b[39mlimit(limits\u001b[38;5;241m=\u001b[39mlimits, user_api\u001b[38;5;241m=\u001b[39muser_api):\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/PhD/Code/Senpai_python/.venv/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:700\u001b[0m, in \u001b[0;36m_kmeans_single_lloyd\u001b[0;34m(X, sample_weight, centers_init, max_iter, verbose, tol, n_threads)\u001b[0m\n\u001b[1;32m    697\u001b[0m strict_convergence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iter):\n\u001b[0;32m--> 700\u001b[0m     \u001b[43mlloyd_iter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcenters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcenters_new\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_in_clusters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcenter_shift\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    712\u001b[0m         inertia \u001b[38;5;241m=\u001b[39m _inertia(X, sample_weight, centers, labels, n_threads)\n",
      "File \u001b[0;32m_k_means_lloyd.pyx:160\u001b[0m, in \u001b[0;36msklearn.cluster._k_means_lloyd.lloyd_iter_chunked_dense\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_k_means_common.pyx:177\u001b[0m, in \u001b[0;36msklearn.cluster._k_means_common._relocate_empty_clusters_dense\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/PhD/Code/Senpai_python/.venv/lib/python3.12/site-packages/numpy/_core/multiarray.py:383\u001b[0m, in \u001b[0;36mwhere\u001b[0;34m(condition, x, y)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    inner(a, b, /)\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    378\u001b[0m \n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, b)\n\u001b[0;32m--> 383\u001b[0m \u001b[38;5;129m@array_function_from_c_func_and_dispatcher\u001b[39m(_multiarray_umath\u001b[38;5;241m.\u001b[39mwhere)\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwhere\u001b[39m(condition, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    385\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    where(condition, [x, y], /)\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;124;03m           [ 0,  3, -1]])\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (condition, x, y)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for nxi,nxe in zip(nxiL, nxeL):\n",
    "    # Definisci gli indici per il ritaglio\n",
    "    nxiS = max(0, nxi - safe_xy)\n",
    "    nxeS = min(Nx, nxe + safe_xy)\n",
    "    NxC = nxe - nxi\n",
    "\n",
    "    # Ciclo sull'asse y\n",
    "    for nyi,nye in zip(nyiL, nyeL):\n",
    "        # Definisci gli indici per il ritaglio\n",
    "        nyiS = max(0, nyi - safe_xy)\n",
    "        nyeS = min(Ny, nye + safe_xy)\n",
    "        NyC = nye - nyi\n",
    "\n",
    "        # Ciclo sull'asse z\n",
    "        for k in k_seq:\n",
    "            # Definisci gli indici per il ritaglio\n",
    "            xinit = max(0, k - safe)\n",
    "            xend = min(Nz, k + win + safe)\n",
    "            NzC = min(Nz, k + win) - k\n",
    "\n",
    "            # Controlla se il ritaglio è già stato elaborato, in tal caso, continua...\n",
    "            \n",
    "            # Visualizza messaggi di stato\n",
    "            print(f'number of clusters is: {clusters}')\n",
    "            print(f'crop is x({nxi}:{nxe}), y({nyi}:{nye})')\n",
    "            print(f'starting with slice {k} over {Nz}, window set to {win}')\n",
    "\n",
    "            # Leggi il ritaglio dell'immagine \n",
    "            # (i) per gestire immagini molto grandi;\n",
    "            # (ii) prima definisci la dimensione effettiva del ritaglio, \n",
    "            \n",
    "            nx = len(range(nxiS, nxeS))\n",
    "            ny = len(range(nyiS, nyeS))\n",
    "            nz = xend - xinit\n",
    "            cIMc = np.zeros((nx, ny, nz), dtype=tp)\n",
    "\n",
    "            # (iii) itera sulle fette dell'immagine originale per leggere il ritaglio\n",
    "\n",
    "            for zz in range(cIMc.shape[2]):\n",
    "                cIMc[:, :, zz] = tifffile.imread(path_img, key=xinit + zz - 1)[nxiS:nxeS, nyiS:nyeS]\n",
    "\n",
    "            # Filtro mediano se sig_G[0] == -1\n",
    "            if sig_G[0] == -1:\n",
    "                print('applying 3x3x3 median filter...')\n",
    "                cIMc = median(cIMc, size=3)\n",
    "\n",
    "            # Fornisce feedback all'utente\n",
    "            print(f'1st of {len(sig_G)} passes...')\n",
    "\n",
    "            # Derivate di primo ordine\n",
    "            if sig_G[0] > 0:\n",
    "                cIMc_smoothed = gaussian(cIMc.astype(np.float32), sigma=[sig_G[0], sig_G[0] * res[0] / res[1], sig_G[0] * res[0] / res[2]])\n",
    "                Gx2, Gy2, Gz2 = np.gradient(cIMc_smoothed)\n",
    "            else:\n",
    "                Gx2, Gy2, Gz2 = np.gradient(cIMc.astype(np.float32))\n",
    "\n",
    "            # Derivate di secondo ordine\n",
    "            Hxx, Hxy, Hxz, Hyy, Hyz, Hzz = hessian_matrix(Gx2, sigma=1)\n",
    "            Gxx2 = Hxx\n",
    "            Gyy2 = Hyy\n",
    "            Gzz2 = Hzz\n",
    "\n",
    "            cIMc = cIMc[\n",
    "                min(safe_xy,nxi):min(NxC+min(safe_xy,nxi), cIMc.shape[0]),\n",
    "                min(safe_xy,nxi):min(NxC+min(safe_xy,nxi), cIMc.shape[1]),\n",
    "                min(safe_xy,k):min(win+min(safe_xy,k), cIMc.shape[2]),\n",
    "            ]\n",
    "\n",
    "            # su GxxKt\n",
    "            GxxKt = Gxx2[\n",
    "                min(safe_xy,nxi):min(NxC+min(safe_xy,nxi), Gxx2.shape[0]),\n",
    "                min(safe_xy,nxi):min(NxC+min(safe_xy,nxi), Gxx2.shape[1]),\n",
    "                min(safe_xy,k):min(win+min(safe_xy,k), Gxx2.shape[2]),\n",
    "            ]\n",
    "\n",
    "            # su GyyKt\n",
    "            GyyKt = Gyy2[\n",
    "                min(safe_xy,nxi):min(NxC+min(safe_xy,nxi), Gyy2.shape[0]),\n",
    "                min(safe_xy,nxi):min(NxC+min(safe_xy,nxi), Gyy2.shape[1]),\n",
    "                min(safe_xy,k):min(win+min(safe_xy,k), Gyy2.shape[2]),\n",
    "            ]\n",
    "\n",
    "            # su GzzKt\n",
    "            GzzKt = Gzz2[\n",
    "                min(safe_xy,nxi):min(NxC+min(safe_xy,nxi), Gzz2.shape[0]),\n",
    "                min(safe_xy,nxi):min(NxC+min(safe_xy,nxi), Gzz2.shape[1]),\n",
    "                min(safe_xy,k):min(win+min(safe_xy,k), Gzz2.shape[2]),\n",
    "            ]\n",
    "\n",
    "            # Salva il ritaglio corrente dell'immagine\n",
    "            with open(os.path.join(f'sl{k}_{nxi}_{nxe}_{nyi}_{nye}.pkl'), 'wb') as f:\n",
    "                pickle.dump({\n",
    "                    'cIMc': cIMc,\n",
    "                    'GxxKt': GxxKt,\n",
    "                    'GyyKt': GyyKt,\n",
    "                    'GzzKt': GzzKt\n",
    "                }, f)\n",
    "            \n",
    "            # Maschera il background a intensità quasi zero per ridurre l'uso della memoria\n",
    "            mask_back = np.where(cIMc.ravel() >= th_back)[0]\n",
    "            resiz_km = np.ones(len(cIMc.ravel()), dtype=np.uint8)\n",
    "\n",
    "            # Definisci lo spazio delle caratteristiche per il k-means\n",
    "            # Ensure the feature vectors are properly scaled\n",
    "            km_in1 = np.column_stack((\n",
    "                cIMc.ravel()[mask_back].astype(np.float32),\n",
    "                GxxKt.ravel()[mask_back],\n",
    "                GyyKt.ravel()[mask_back],\n",
    "                GzzKt.ravel()[mask_back]\n",
    "            ))\n",
    "\n",
    "            # Initialize TOT_KM1 with proper shape\n",
    "            TOT_KM1 = np.ones((NxC, NyC, NzC), dtype=tp)\n",
    "\n",
    "            # Clustering k-means only if enough samples\n",
    "            kmeans = KMeans(n_clusters=clusters, n_init=10, max_iter=1000, random_state=42)\n",
    "            labels = kmeans.fit_predict(km_in1.astype(np.float32))\n",
    "            resiz_km[mask_back] = labels.astype(np.uint8)\n",
    "            TOT_KM1 = resiz_km.reshape((NxC, NyC, NzC))\n",
    "                \n",
    "\n",
    "            # Save the k-means clustering results for the current crop\n",
    "            with open(os.path.join(f'sl{k}_{nxi}_{nxe}_{nyi}_{nye}.pkl'), 'ab') as f:\n",
    "                    pickle.dump({'TOT_KM1': TOT_KM1}, f)\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of clusters is: 6\n",
      "crop is x(0:256), y(0:256)\n",
      "starting with slice 0 over 143, window set to 149\n",
      "1st of 1 passes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x1/cw0t9qw9547b5jd05cm3d2vr0000gn/T/ipykernel_97569/2095941355.py:60: FutureWarning: use_gaussian_derivatives currently defaults to False, but will change to True in a future version. Please specify this argument explicitly to maintain the current behavior\n",
      "  Hxx, Hxy, Hxz, Hyy, Hyz, Hzz = hessian_matrix(Gx2, sigma=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cIMc shape: (259, 259, 143)\n",
      "\n",
      "cIMc shape: (256, 256, 143)\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 8961260 is out of bounds for axis 0 with size 8961260",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[139], line 115\u001b[0m\n\u001b[1;32m    109\u001b[0m resiz_km \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(cIMc\u001b[38;5;241m.\u001b[39mravel()), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Definisci lo spazio delle caratteristiche per il k-means\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# Ensure the feature vectors are properly scaled\u001b[39;00m\n\u001b[1;32m    113\u001b[0m km_in1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcolumn_stack((\n\u001b[1;32m    114\u001b[0m     cIMc\u001b[38;5;241m.\u001b[39mravel()[mask_back]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[0;32m--> 115\u001b[0m     \u001b[43mGxxKt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask_back\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[1;32m    116\u001b[0m     GyyKt\u001b[38;5;241m.\u001b[39mravel()[mask_back],\n\u001b[1;32m    117\u001b[0m     GzzKt\u001b[38;5;241m.\u001b[39mravel()[mask_back]\n\u001b[1;32m    118\u001b[0m ))\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Initialize TOT_KM1 with proper shape\u001b[39;00m\n\u001b[1;32m    121\u001b[0m TOT_KM1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((NxC, NyC, NzC), dtype\u001b[38;5;241m=\u001b[39mtp)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 8961260 is out of bounds for axis 0 with size 8961260"
     ]
    }
   ],
   "source": [
    "nxi = nxiL[0]\n",
    "nxe = nxeL[0]\n",
    "# Definisci gli indici per il ritaglio\n",
    "nxiS = max(0, nxi - safe_xy)\n",
    "nxeS = min(Nx, nxe + safe_xy)\n",
    "NxC = nxe - nxi\n",
    "\n",
    "# Ciclo sull'asse y\n",
    "nyi = nyiL[0]\n",
    "nye = nyeL[0]\n",
    "# Definisci gli indici per il ritaglio\n",
    "nyiS = max(0, nyi - safe_xy)\n",
    "nyeS = min(Ny, nye + safe_xy)\n",
    "NyC = nye - nyi\n",
    "\n",
    "# Ciclo sull'asse z\n",
    "for k in k_seq:\n",
    "    # Definisci gli indici per il ritaglio\n",
    "    xinit = max(0, k - safe)\n",
    "    xend = min(Nz, k + win + safe)\n",
    "    NzC = min(Nz, k + win) - k\n",
    "\n",
    "    # Controlla se il ritaglio è già stato elaborato, in tal caso, continua...\n",
    "    \n",
    "    # Visualizza messaggi di stato\n",
    "    print(f'number of clusters is: {clusters}')\n",
    "    print(f'crop is x({nxi}:{nxe}), y({nyi}:{nye})')\n",
    "    print(f'starting with slice {k} over {Nz}, window set to {win}')\n",
    "\n",
    "    # Leggi il ritaglio dell'immagine \n",
    "    # (i) per gestire immagini molto grandi;\n",
    "    # (ii) prima definisci la dimensione effettiva del ritaglio, \n",
    "    \n",
    "    nx = len(range(nxiS, nxeS))\n",
    "    ny = len(range(nyiS, nyeS))\n",
    "    nz = xend - xinit\n",
    "    cIMc = np.zeros((nx, ny, nz), dtype=tp)\n",
    "\n",
    "    # (iii) itera sulle fette dell'immagine originale per leggere il ritaglio\n",
    "\n",
    "    for zz in range(cIMc.shape[2]):\n",
    "        cIMc[:, :, zz] = tifffile.imread(path_img, key=xinit + zz - 1)[nxiS:nxeS, nyiS:nyeS]\n",
    "\n",
    "    # Filtro mediano se sig_G[0] == -1\n",
    "    if sig_G[0] == -1:\n",
    "        print('applying 3x3x3 median filter...')\n",
    "        cIMc = median(cIMc, size=3)\n",
    "\n",
    "    # Fornisce feedback all'utente\n",
    "    print(f'1st of {len(sig_G)} passes...')\n",
    "\n",
    "    # Derivate di primo ordine\n",
    "    if sig_G[0] > 0:\n",
    "        cIMc_smoothed = gaussian(cIMc.astype(np.float32), sigma=[sig_G[0], sig_G[0] * res[0] / res[1], sig_G[0] * res[0] / res[2]])\n",
    "        Gx2, Gy2, Gz2 = np.gradient(cIMc_smoothed)\n",
    "    else:\n",
    "        Gx2, Gy2, Gz2 = np.gradient(cIMc.astype(np.float32))\n",
    "\n",
    "    # Derivate di secondo ordine\n",
    "    Hxx, Hxy, Hxz, Hyy, Hyz, Hzz = hessian_matrix(Gx2, sigma=1)\n",
    "    Gxx2 = Hxx\n",
    "    Gyy2 = Hyy\n",
    "    Gzz2 = Hzz\n",
    "\n",
    "    cIMc = cIMc[\n",
    "        min(safe_xy,nxi):min(NxC+min(safe_xy,nxi), cIMc.shape[0]),\n",
    "        min(safe_xy,nxi):min(NxC+min(safe_xy,nxi), cIMc.shape[1]),\n",
    "        min(safe_xy,k):min(win+min(safe_xy,k), cIMc.shape[2]),\n",
    "    ]\n",
    "    print(f'cIMc shape: {cIMc.shape}\\n')\n",
    "    # su GxxKt\n",
    "    GxxKt = Gxx2[\n",
    "        max(0, safe_xy):min(NxC, safe_xy + NxC),\n",
    "        max(0, safe_xy):min(NyC, safe_xy + NyC),\n",
    "        max(0, safe):min(win, safe + win)\n",
    "    ]\n",
    "\n",
    "    # su GyyKt\n",
    "    GyyKt = Gyy2[\n",
    "        max(0, safe_xy):min(NxC, safe_xy + NxC),\n",
    "        max(0, safe_xy):min(NyC, safe_xy + NyC),\n",
    "        max(0, safe):min(win, safe + win)\n",
    "    ]\n",
    "\n",
    "    # su GzzKt\n",
    "    GzzKt = Gzz2[\n",
    "        max(0, safe_xy):min(NxC, safe_xy + NxC),\n",
    "        max(0, safe_xy):min(NyC, safe_xy + NyC),\n",
    "        max(0, safe):min(win, safe + win)\n",
    "    ]\n",
    "\n",
    "    # Salva il ritaglio corrente dell'immagine\n",
    "    with open(os.path.join(f'sl{k}_{nxi}_{nxe}_{nyi}_{nye}.pkl'), 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'cIMc': cIMc,\n",
    "            'GxxKt': GxxKt,\n",
    "            'GyyKt': GyyKt,\n",
    "            'GzzKt': GzzKt\n",
    "        }, f)\n",
    "    \n",
    "    # Maschera il background a intensità quasi zero per ridurre l'uso della memoria\n",
    "    mask_back = np.where(cIMc.ravel() >= th_back)[0]\n",
    "    resiz_km = np.ones(len(cIMc.ravel()), dtype=np.uint8)\n",
    "\n",
    "    # Definisci lo spazio delle caratteristiche per il k-means\n",
    "    # Ensure the feature vectors are properly scaled\n",
    "    km_in1 = np.column_stack((\n",
    "        cIMc.ravel()[mask_back].astype(np.float32),\n",
    "        GxxKt.ravel()[mask_back],\n",
    "        GyyKt.ravel()[mask_back],\n",
    "        GzzKt.ravel()[mask_back]\n",
    "    ))\n",
    "\n",
    "    # Initialize TOT_KM1 with proper shape\n",
    "    TOT_KM1 = np.ones((NxC, NyC, NzC), dtype=tp)\n",
    "\n",
    "    # Clustering k-means only if enough samples\n",
    "    if km_in1.shape[0] >= 10:\n",
    "        try:\n",
    "            kmeans = KMeans(n_clusters=clusters, n_init=10, max_iter=1000, random_state=42)\n",
    "            labels = kmeans.fit_predict(km_in1.astype(np.float32))\n",
    "            resiz_km[mask_back] = labels.astype(np.uint8)\n",
    "            TOT_KM1 = resiz_km.reshape((NxC, NyC, NzC))\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: K-means clustering failed with error: {e}\")\n",
    "\n",
    "    # Save the k-means clustering results for the current crop\n",
    "    try:\n",
    "        with open(os.path.join(f'sl{k}_{nxi}_{nxe}_{nyi}_{nye}.pkl'), 'ab') as f:\n",
    "            pickle.dump({'TOT_KM1': TOT_KM1}, f)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Failed to save results: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
